#!/usr/bin/env python3.6
# coding: utf-8

from itertools import combinations

import networkx as nx
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from networkx.drawing.nx_pydot import graphviz_layout
from sklearn import linear_model
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures

rankings = pd.read_csv('./data/FIFA_Ranking.csv')
rankings = rankings.loc[:, [
    'rank', 'country_full', 'country_abrv', 'cur_year_avg_weighted',
    'rank_date', 'two_year_ago_weighted', 'three_year_ago_weighted'
]]
rankings = rankings.replace({"IR Iran": "Iran"})
rankings[
    'weighted_points'] = rankings['cur_year_avg_weighted'] + rankings['two_year_ago_weighted'] + rankings['three_year_ago_weighted']
rankings['rank_date'] = pd.to_datetime(rankings['rank_date'])

matches = pd.read_csv('./data/results.csv')
matches = matches.replace({'Germany DR': 'Germany', 'China': 'China PR'})
matches['date'] = pd.to_datetime(matches['date'])

world_cup = pd.read_csv('./data/WorldCup2018Dataset.csv')
world_cup = world_cup.loc[:, [
    'Team', 'Group', 'First match \nagainst', 'Second match\n against',
    'Third match\n against'
]]
world_cup = world_cup.dropna(how='all')
world_cup = world_cup.replace({
    "IRAN": "Iran",
    "Costarica": "Costa Rica",
    "Porugal": "Portugal",
    "Columbia": "Colombia",
    "Korea": "Korea Republic"
})
world_cup = world_cup.set_index('Team')

# # Feature extraction
#
# I join the matches with the ranks of the different teams.
#
# Then extract some features:
# - point and rank differences
# - if the game was for some stakes, because my naive view was that typically friendly matches are harder to predict (TODO differentiate the WC matches from the rest)
# - how many days the different teams were able to rest but this turned out to be not important enough to be worth the hassle
# - include the participant countries as a one hot vector but that did not appear to be a strong predictor either

# In[2]:

# I want to have the ranks for every day
rankings = rankings.set_index(['rank_date']).groupby(
    ['country_full'], group_keys=False).resample('D').first().fillna(
        method='ffill').reset_index()

# join the ranks
matches = matches.merge(
    rankings,
    left_on=['date', 'home_team'],
    right_on=['rank_date', 'country_full'])
matches = matches.merge(
    rankings,
    left_on=['date', 'away_team'],
    right_on=['rank_date', 'country_full'],
    suffixes=('_home', '_away'))

# In[3]:

# feature generation
matches['rank_difference'] = matches['rank_home'] - matches['rank_away']
matches['average_rank'] = (matches['rank_home'] + matches['rank_away']) / 2
matches[
    'point_difference'] = matches['weighted_points_home'] - matches['weighted_points_away']
matches['score_difference'] = matches['home_score'] - matches['away_score']
matches['is_won'] = matches['score_difference'] > 0  # take draw as lost
matches['is_stake'] = matches['tournament'] != 'Friendly'

# I tried earlier rest days but it did not turn to be useful
max_rest = 30
matches['rest_days'] = matches.groupby('home_team').diff()[
    'date'].dt.days.clip(0, max_rest).fillna(max_rest)

# I tried earlier the team as well but that did not make a difference either
matches['wc_participant'] = matches['home_team'] * matches['home_team'].isin(
    world_cup.index.tolist())
matches['wc_participant'] = matches['wc_participant'].replace({'': 'Other'})
matches = matches.join(pd.get_dummies(matches['wc_participant']))

# # Modeling
#
# I used a simple Logistic regression, which yielded already rather good performance

# In[4]:

X, y = matches.loc[:, [
    'average_rank', 'rank_difference', 'point_difference', 'is_stake'
]], matches['is_won']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

logreg = linear_model.LogisticRegression(C=1e-5)
features = PolynomialFeatures(degree=2)
model = Pipeline([('polynomial_features', features), ('logistic_regression',
                                                      logreg)])
model = model.fit(X_train, y_train)

# figures
fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
plt.figure(figsize=(15, 5))
ax = plt.subplot(1, 3, 1)
ax.plot([0, 1], [0, 1], 'k--')
ax.plot(fpr, tpr)
ax.set_title('AUC score is {0:0.2}'.format(
    roc_auc_score(y_test,
                  model.predict_proba(X_test)[:, 1])))
ax.set_aspect(1)

ax = plt.subplot(1, 3, 2)
cm = confusion_matrix(y_test, model.predict(X_test))
ax.imshow(cm, cmap='Blues', clim=(0, cm.max()))

ax.set_xlabel('Predicted label')
ax.set_title('Performance on the Test set')

ax = plt.subplot(1, 3, 3)
cm = confusion_matrix(y_train, model.predict(X_train))
ax.imshow(cm, cmap='Blues', clim=(0, cm.max()))
ax.set_xlabel('Predicted label')
ax.set_title('Performance on the Training set')
pass

# I consider this pretty good performance, minding that soccer matches have typically only few goals scored and therefore making their outcome even more unpredictable. Nevertheless,
# let's look at the bad predictions and see where we are making mistakes more often.

# In[5]:

features = ['average_rank', 'rank_difference', 'point_difference']
wrongs = y_test != model.predict(X_test)

for feature in features:
    plt.figure()
    plt.title(feature)
    X_test.loc[wrongs, feature].plot.kde()
    X.loc[:, feature].plot.kde()
    plt.legend(['wrongs', 'all'])

print("Stakes distribution in the wrong predictions")
print(X_test.loc[wrongs, 'is_stake'].value_counts() / wrongs.sum())
print("Stakes distribution overall")
print(X['is_stake'].value_counts() / X.shape[0])

# From these figures, we read
# - we predict worse for closer ranks
# - lower ranks in general
# - and somewhat for matches with no stakes (Friendly here)
#
# Luckily, this implies that for the world cup our predicitons may be somewhat even better

# # World Cup simulation

# ## Group rounds

# In[6]:

# let's define a small margin when we safer to predict draw then win
margin = 0.05

# let's define the rankings at the time of the World Cup
world_cup_rankings = rankings.loc[
    (rankings['rank_date'] == rankings['rank_date'].max())
    & rankings['country_full'].isin(world_cup.index.unique())]
world_cup_rankings = world_cup_rankings.set_index(['country_full'])

# In[7]:

opponents = [
    'First match \nagainst', 'Second match\n against', 'Third match\n against'
]

world_cup['points'] = 0
world_cup['total_prob'] = 0

for group in set(world_cup['Group']):
    print('___Starting group {}:___'.format(group))
    for home, away in combinations(
            world_cup.query('Group == "{}"'.format(group)).index, 2):
        print("{} vs. {}: ".format(home, away), end='')
        row = pd.DataFrame(
            np.array([[np.nan, np.nan, np.nan, True]]), columns=X_test.columns)
        home_rank = world_cup_rankings.loc[home, 'rank']
        home_points = world_cup_rankings.loc[home, 'weighted_points']
        opp_rank = world_cup_rankings.loc[away, 'rank']
        opp_points = world_cup_rankings.loc[away, 'weighted_points']
        row['average_rank'] = (home_rank + opp_rank) / 2
        row['rank_difference'] = home_rank - opp_rank
        row['point_difference'] = home_points - opp_points

        home_win_prob = model.predict_proba(row)[:, 1][0]
        world_cup.loc[home, 'total_prob'] += home_win_prob
        world_cup.loc[away, 'total_prob'] += 1 - home_win_prob

        points = 0
        if home_win_prob <= 0.5 - margin:
            print("{} wins with {:.2f}".format(away, 1 - home_win_prob))
            world_cup.loc[away, 'points'] += 3
        if home_win_prob > 0.5 - margin:
            points = 1
        if home_win_prob >= 0.5 + margin:
            points = 3
            world_cup.loc[home, 'points'] += 3
            print("{} wins with {:.2f}".format(home, home_win_prob))
        if points == 1:
            print("Draw")
            world_cup.loc[home, 'points'] += 1
            world_cup.loc[away, 'points'] += 1

# ## Single-elimination rounds

# In[8]:

pairing = [0, 3, 4, 7, 8, 11, 12, 15, 1, 2, 5, 6, 9, 10, 13, 14]

world_cup = world_cup.sort_values(
    by=['Group', 'points', 'total_prob'], ascending=False).reset_index()
next_round_wc = world_cup.groupby('Group').nth([0, 1])  # select the top 2
next_round_wc = next_round_wc.reset_index()
next_round_wc = next_round_wc.loc[pairing]
next_round_wc = next_round_wc.set_index('Team')

finals = ['round_of_16', 'quarterfinal', 'semifinal', 'final']

labels = list()
odds = list()

for f in finals:
    print("___Starting of the {}___".format(f))
    iterations = int(len(next_round_wc) / 2)
    winners = []

    for i in range(iterations):
        home = next_round_wc.index[i * 2]
        away = next_round_wc.index[i * 2 + 1]
        print("{} vs. {}: ".format(home, away), end='')
        row = pd.DataFrame(
            np.array([[np.nan, np.nan, np.nan, True]]), columns=X_test.columns)
        home_rank = world_cup_rankings.loc[home, 'rank']
        home_points = world_cup_rankings.loc[home, 'weighted_points']
        opp_rank = world_cup_rankings.loc[away, 'rank']
        opp_points = world_cup_rankings.loc[away, 'weighted_points']
        row['average_rank'] = (home_rank + opp_rank) / 2
        row['rank_difference'] = home_rank - opp_rank
        row['point_difference'] = home_points - opp_points

        home_win_prob = model.predict_proba(row)[:, 1][0]
        if model.predict_proba(row)[:, 1] <= 0.5:
            print("{0} wins with probability {1:.2f}".format(
                away, 1 - home_win_prob))
            winners.append(away)
        else:
            print("{0} wins with probability {1:.2f}".format(
                home, home_win_prob))
            winners.append(home)

        labels.append("{}({:.2f}) vs. {}({:.2f})".format(
            world_cup_rankings.loc[home, 'country_abrv'], 1 / home_win_prob,
            world_cup_rankings.loc[away, 'country_abrv'],
            1 / (1 - home_win_prob)))
        odds.append([home_win_prob, 1 - home_win_prob])

    next_round_wc = next_round_wc.loc[winners]
    print("\n")

# # Let's see a visualization

# In[ ]:

node_sizes = pd.DataFrame(list(reversed(odds)))
scale_factor = 0.3  # for visualization
G = nx.balanced_tree(2, 3)
pos = graphviz_layout(G, prog='twopi', args='')
centre = pd.DataFrame(pos).mean(axis=1).mean()

plt.figure(figsize=(10, 10))
ax = plt.subplot(1, 1, 1)
# add circles
circle_positions = [(235, 'black'), (180, 'blue'), (120, 'red'), (60,
                                                                  'yellow')]
[
    ax.add_artist(plt.Circle((centre, centre), cp, color='grey', alpha=0.2))
    for cp, c in circle_positions
]

# draw first the graph
nx.draw(
    G,
    pos,
    node_color=node_sizes.diff(axis=1)[1].abs().pow(scale_factor),
    node_size=node_sizes.diff(axis=1)[1].abs().pow(scale_factor) * 2000,
    alpha=1,
    cmap='Reds',
    edge_color='black',
    width=10,
    with_labels=False)

# draw the custom node labels
shifted_pos = {
    k: [(v[0] - centre) * 0.9 + centre, (v[1] - centre) * 0.9 + centre]
    for k, v in pos.items()
}
nx.draw_networkx_labels(
    G,
    pos=shifted_pos,
    bbox=dict(
        boxstyle="round,pad=0.3", fc="white", ec="black", lw=.5, alpha=1),
    labels=dict(zip(reversed(range(len(labels))), labels)))

texts = ((10, 'Best 16', 'black'), (70, 'Quarter-\nfinal', 'blue'),
         (130, 'Semifinal', 'red'), (190, 'Final', 'yellow'))
[
    plt.text(
        p, centre + 20, t, fontsize=12, color='grey', va='center', ha='center')
    for p, t, c in texts
]
plt.axis('equal')
plt.title('Single-elimination phase\npredictions with fair odds', fontsize=20)
plt.show()

# Fin
